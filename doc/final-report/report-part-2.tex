% Progress report for CS565
 
\documentclass[a4paper,12pt]{article}
\usepackage{algorithm, algorithmic}

\begin{document}

\newpage


\section{Shear-Warp Factorization}

\subsection{A Hybrid Algorithm}

To summarize our findings about image order and object order
algorithms, we can state that they offer the following advantages
\begin{itemize}
\item In image space algorithms high-quality resampling can be
  implemented efficiently, and the optimization by early ray
  termination is easily achievable.
\item In object space algorithms, the addressing arithmetic is simpler
  and they offer an optimization due to spatial data structures since
  they access the volume data in storage order.
\end{itemize}

Therefore, both classes of algorithms make distinct kind of
improvements over the simplest possible implementation. An algorithm
that would attain the advantages of both kinds would be desirable.
However, such an algorithm can be neither strictly an image space
algorithm, nor an object space one. Then, we should look for an
algorithm that falls into both classes. Such an algorithm would assume
both the early ray termination capability of ray casters, and the
spanning advantages of splatting algorithms.

In this section, we describe a framework for obtaining an algorithm
that is edible in both manners. The basic change is that we operate in
an intermediate space that makes translation from the object space to
image space and in the reverse direction a trivial task. We accomplish 
this by factoring the viewing transformation from the volume to the
image. This process which is called shear-warp factorization involves first
shearing the volume so that the volume is easier to process,
secondly obtaining an intermediate image that is simpler to compute
directly from that volume, and finally warping the intermediate image
to the final image. The factorization can be accomplished both for
affine viewing transformations and perspective viewing
transformations, however we will examine only affine viewing
transformations since they give rise to slightly simpler algorithms.
We also describe the properties of the factorization that allow us to
implement a volume rendering algorithm that is faster than both pure
object space and pure image space algorithms.

\subsection{Obtaining an Intermediate Space}

Object space algorithms usually suffer from the complicated mapping
from volume to image; this difficulty prevents efficient filtering and
projection. Also in image space algorithms this difficulty causes
costly arithmetic while projecting pixels to volume. That is why, we
choose to work in an intermediate space that has a simple mapping from
volume to image. Since the simplest case possible is that the cast
rays are orthogonal to the object space, we transform the volume to a
new volume which will make this possible and render an intermediate
image which will be warped to the resulting image.

Consider the rays that are cast from the image plane in the case of
parallel projection; an axis in the object space makes the least angle
with all the rays. This axis is called the principal viewing axis and
plays a big role in the factorization. We conceive the slices along
the principal viewing direction. The kind of transformation that we
should perform in order to align viewing rays with the principal
viewing axis turns out to be very simple. If we place a
secondary image plane attached to the closest slice, the viewing rays
of it are perpendicular to the object space. When we apply the regular
deformation shear to the slices in the direction of the principal
viewing axis so that viewing rays of the secondary image plane make
the same angle with the slices that the viewing rays of the primary
image plane makes with the original slices , we would have obtained a space
with the desired property. The only remaining problem would be to
compute the primary image from the secondary image.

We call the image on the secondary image plane the intermediate
image. The intermediate image only requires a 2D warp in order to take
us to the final image.
\footnote{An analogy could perhaps better illustrate the solution. Assume that a
block of highly detailed gel is being examined by a camera.
In a dark room with a point light source, the picture will contain
the kind of image that we wish to
construct. Now also imagine that the block of gel stands on top of a
table with a glass top and that the camera views the gel from below.
A refractor is fixed under the table that can bend the light to
a desired angle. The picture will be deformed. However if you deform
the gel in a certain way, you can obtain the original picture of the
gel.}

The intermediate space with the orthogonality property gives us the
simplest possible mapping from object space to image space since a
projection of the slice along the principal viewing axis is equivalent
to a translation of the slice.

The only addition for factorization of perspective viewing
transformation is that each slice has to be scaled after sheared.

\subsection{A Brute Force Algorithm}

Using the shear warp algorithm it is possible to write a
straightforward volume rendering algorithm (see
alg. \ref{alg:bf-sw}). The
 algorithm, without implementing any of the desired optimizations, is
 not much better then a brute force ray casting algorithm, except that
 the arithmetic overhead has been significantly reduced.

\begin{algorithm}
\caption{Brute-Force-Shear-Warp}
\label{alg:bf-sw}
\begin{algorithmic}
\FOR{ $z_0 \gets 1$ to VolumeDepth}
\FOR{ $y_i \gets 1$ to ImageHeight}
\FOR{ $x_i \gets 1$ to ImageWidth}
\FORALL{ $y_o$ in $ResamplingFilter(x_i,y_i)$ }
\FORALL{ $x_o$ in $ResamplingFilter(x_i,y_i)$ }
\STATE $Contribute_Voxel(Voxel[x_0,y_0,z_0],ImagePixel[x_i,y_i])$
\ENDFOR
\ENDFOR
\ENDFOR
\ENDFOR
\ENDFOR
\end{algorithmic}
\end{algorithm}

It is a hybrid algorithm because what it does is simply iterating the
slices in front to back order, which have spaces identical with the
image space. The iterated slices are simply combined with the
\textbf{over} operator to form the intermediate image.

In order to do the factorization for both parallel and perspective
viewing transformation, one considers the equation

\begin{equation}
 M_{view} = M_{warp} \cdot M_{shear}
\end{equation}

%The derivations are lengthy and they can be found in \cite{Lacroute}.
To summarize, the parallel projection which we are more concerned with
takes the viewing vector assuming that principal viewing axis is $+z$
axis of object space $v_i = (0,0,1) $ and derives $v_0$, the
viewing direction vector transformed to object space, where $v_i =
M_{{view},{3 \times 3}}$. The shear necessary in both $x$ and $y$
directions are simply computed as $s_x = -(v_{0,x})/v_{0,z} \ and s_y
= - v_{0,y}/v_{0,z}$.

\subsection{How Properties Permit Optimizations}

In the preceding subsections, we had claimed that our hybrid volume
rendering framework allows both of the significant optimizations,
namely early ray termination and speedups from spatial data
structures, to be incorporated. We now show how the orthogonality and
equivalence of the intermediate image space and subspaces of the
object spaces in slices may lead to better opportunities for
optimization.

\subsubsection{Overview}

The main advantage of the hybrid algorithm is that we can
simultaneously traverse both object space and image space without high
cost incurring. Since the intermediate space has the property that
slice spaces are identical to intermediate image space and the
property that viewing rays are parallel to principal viewing axis,
only a simple translation suffices to project an entire slice onto the
intermediate image plane. Thus, as we traverse a slice along the
principal viewing axis, we can switch arbitrarily to the intermediate
image as well.

This procedure is assistive in that it provides us to construct view
independent spatial data structures in a preprocessing step prior to
all rendering assuming that the classification remains
constant.\footnote{A change in classification implies that all opacity
  values are going to be re evaluated.} All that is required will be
the encoding of the volume for each principal viewing axis possible,
which amounts to three.

Among others, the particularly interesting spatial encoding is run
length encoding, since it gives us the opportunity to implement both
transparent voxel omission and early ray termination.

\subsubsection{Transparent Voxel Omission}

We have indicated that it's possible to construct view independent
spatial encoding of the volume. The encoding of interest to us is run
length encoding since it can allow us to skip transparent voxels while
processing a slice. Recalling that we can span a slice in both object
space and image space efficiently and simultaneously,
it will be clear that a run length encoding can give us the ability 
to distinguish consecutive voxels in a slice that should be omitted
from evaluation. Since the run length encoding of the volume is going
to be performed once while preprocessing the volume, the user will
benefit from this optimization while interacting with the volume. As
for the non transparent voxels, we try to make as least passes as
possible. In practice, a very tight loop that functionally composes
resampling, shading and composition is desirable since multiple passes
would give rise to overheads due to decoding.


\subsubsection{Early Ray Termination}
In ray casting algorithms, the backward projection iteration is
terminated whenever the accumulated voxel is considered opaque. All
remaining voxels are determined to be occluded, hence there is little need
to shade them. For the early ray termination to work, a front to back
order traversal of the object space is required. In the brute force
algorithm \ref{alg:bf-sw} we already do that. However, a second
requirement has to be fulfilled. An efficient memoization of the
opacity of pixels must be supplied. In particular, we wish to skip
consecutive pixels that are all opaque within a scanline. 
 While the slice is being processed, the opacity data
on the intermediate image is also considered so that the parts of the
slice that would be projected onto the intermediate image are skipped
immediately.

Considering the order of our algorithm, what we do may be regarded as
casting slices through an intermediate volume in front-to-back
order. Then, if the memoization is handled efficiently, the early ray
termination optimization will have been implemented as fast as on a
traditional ray caster.

Even if we merely checked whether we needed to evaluate a pixel, this
would give a valuable speed up. However, it is possible to even
further that with the employment of a disjoint set implementation. In
disjoint sets, only a member of the set represent a set, and there
exist efficient algorithms for disjoint set operations. If we take
consecutive opaque pixels as disjoint sets, then whenever two such
sets become neighbors, we will perform the Union operation and
whenever we wish to skip over one we will perform the Find
operation. In our Algorithms textbook, there is a complete elaboration
of the subject. In order to implement the disjoint sets with forest of
trees and path compression optimization, within the intermediate
image, pixel indices for each pixel are stored.

\subsubsection{Resampling and the Opacity Correction}
In the shear-warp factorization algorithms, we stick to 2D resampling
since a 3D resampling would be considerably less efficient. However,
a 2D bilinear interpolation filter that works by interpolating two
scanlines of voxel data to produce one sampled voxel scanline is
observed to produce high quality results. In
addition to this, the resampling must be wary of the two main
optimizations in the rendering algorithm since the optimizations would
be corrupt otherwise. That is, it those voxels that are
non-transparent and non-occluded that are actually resampled.

Another issue is the opacity correction which should be addressed by
any object space renderer. The correction may be applied just before
resampling, and optimized by consulting a view dependent LUT.


\section{Development Platform and Strategy}

\subsection{Language and Platform choice}

Already, the public domain VolPack library implements the ideas
presented in an OpenGL like C library. However, it is not our
purpose to fit a user interface and build a complete visualisation
application based on the library. In agreement with this, the software
components we create must not be an exact replica of the VolPack
software. Instead, we wish to implement a more object oriented
approach in which we keep all the efficiency
concerns. Since C++ has recently proven to be a very decisive tool for
scientific applications, we have chosen C++ as our implementation
platform. Although the study of algorithms has not been an easy task,
it is our belief that the use of standard library and generic
programming will give us quite a leverage. The platform for
development is set as GNU/Linux and the g++ compiler naturally.

\subsection{Plan}

The development will follow implementation of two algorithms first of
which is the efficient ray caster and the second being parallel
projection shear-warp algorithm. They will be contained in the same
user interface, and we want the user to be able to try both algorithms
on the same data. Since we work with regular grids, we will probably adapt
Stanford CG Lab's file format.

The resampling, shading and composition of voxels are virtually
identical in both cases, so we will achieve the implementation in the
following order.
\begin{enumerate}
\item Establishing mathematical primitives
\item Object Design and Implementation for the Volume Visualisation domain
\item Implementation of I/O and helper methods
\item GUI Design and Implementation (gradual)
\item Implementation of Efficient Ray Casting algorithm
\item Implementation of Shear Warp Algorithm in four phases
  \begin{itemize}
   \item Implementation of Shear-Warp factorization math and objects
   \item Implementation of Pre-Processing Pass
   \item Implementation of Shear-Warp factorization algorithm that
     incorporates Transparent Voxel Omission
   \item Implementation of the Early Ray Termination Optimization
  \end{itemize}
\end{enumerate}

\subsection{Future Work and Program Licensing}

This will only be a sample implementation. Much better functionality would be
required for a state-of-the-art visualisation package. Implementing
all the improvements over the shear-warp factorization algorithm is a
demanding task, however implementing those upon our framework would
facilitate code reuse.

The second sensible area for future work is parallelizing the
sequential shear-warp factorization algorithm. The intermediate space
lends itself to a natural and efficient parallelisation, so it must
not require a complete rewrite.

We wish to put the program under GPL, since it can be a basis for
free medical visualisation programs utilizing the DICOM3.0 library by
Eray \"Ozkural, and would encourage other people to improve on it.






\end{document}
